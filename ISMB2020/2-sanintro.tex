\section{Introduction}

A major issue while working with recent omics data is the availability of greater number of features in comparison to the available number of samples. It may be great to argue that the larger the feature set, the better the classification that is possible. However, in a general setting, not all of these features will be necessary for optimal classification. Only a selected number of significant features when used with the classifier can lead to optimal classification. A large part of the remaining features are not too significant and could be either noise, irrelevant to the study or even redundant~\citep{pirgazi2019efficient}. The use of such insignificant features can lead to unwanted computational complexities and hamper the performance of the system. This is more pronounced when working with data having high dimensionality. Thus, it is essential to identify the set of significant features that can provide us with the optimal classification and clustering. For this to be accomplished, we need a robust method that can eliminate the redundant features and noise that do not have any information about the labels. 


An optimally selected set of features optimizes the performance of the models and also helps in alleviating the effect of \emph{overfitting} and \emph{high-dimensionality}. Along with the above benefits, selecting the appropriate features helps in easier interpretation of the model and thus its predictions. Also, the use of the gratuitous features can significantly impact the training speeds and the accuracy of the learning models. Overall, appropriate feature selection can provide the following advantages: (a)~reduced cost for computation and storage, (b)~adequate use of the available sample set for improved performance, (c)~improved timing for classification and thus predictions, (d)~easier interpretation of the the data and thus the final predictions. 


Our major contributions in this paper is two fold: (a)~we create a new variant of the standard autoencoder by introducing the use of a concrete relaxation discrete random variable selection layer for encoding, (b)~evaluation of the performance of the proposed approach on coding and non-coding gene expression datasets, (c)~modifying the codebase of a standard autoencode to realize the proposed approach. Our initial evaluations show the improved performance of the proposed approach in comparison to the existing state-of-the-art methods in identifying the top 100 coding and non-coding genes that can distinguish 33 different types of cancers.  
The results also show a significant increase in the classification performance up to 99\%.

